{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æµ‹è¯•ä¸€ä¸‹å¯¹150ä¸‡æ•°æ®çš„æ£€ç´¢é€Ÿåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "    input_dir=\"./docs\",\n",
    "    recursive=True,\n",
    "    required_exts=[\".docx\"], # åªéœ€è¦wordæ–‡æ¡£\n",
    ")\n",
    "\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists(\"/root/ZeroKaraNoRAG/models/bce-embedding-base_v1/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/hub/models--maidalun1020--bce-embedding-base_v1/snapshots/b0de52f5ffc2106da6b5a8b68577ed9052ea1a6f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import os\n",
    "HF_TOKEN=\"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\" # ä½ çš„huggingface token\n",
    "os.system(f\"huggingface-cli download --resume-download maidalun1020/bce-embedding-base_v1 --local-dir ./models/bce-embedding-base_v1 --local-dir-use-symlinks False --token {HF_TOKEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/bce-embedding-base_v1/config.json\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"models/bce-embedding-base_v1\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.39.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file models/bce-embedding-base_v1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMRobertaModel.\n",
      "\n",
      "All the weights of XLMRobertaModel were initialized from the model checkpoint at models/bce-embedding-base_v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\n",
      "loading file sentencepiece.bpe.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"models/bce-embedding-base_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¢ç´¢åµŒå…¥æ¨¡å‹çš„ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/cook/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "SentenceTransformer                                               --\n",
       "â”œâ”€Transformer: 1-1                                                --\n",
       "â”‚    â””â”€XLMRobertaModel: 2-1                                       --\n",
       "â”‚    â”‚    â””â”€XLMRobertaEmbeddings: 3-1                             192,398,592\n",
       "â”‚    â”‚    â””â”€XLMRobertaEncoder: 3-2                                85,054,464\n",
       "â”‚    â”‚    â””â”€XLMRobertaPooler: 3-3                                 590,592\n",
       "â”œâ”€Pooling: 1-2                                                    --\n",
       "â”œâ”€Normalize: 1-3                                                  --\n",
       "==========================================================================================\n",
       "Total params: 278,043,648\n",
       "Trainable params: 278,043,648\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel,AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torchinfo import summary\n",
    "embedding_model_original=SentenceTransformer(\"models/bce-embedding-base_v1\")\n",
    "embedding_tokenizer=AutoTokenizer.from_pretrained(\"models/bce-embedding-base_v1\")\n",
    "summary(embedding_model_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æµ‹è¯•åˆ†è¯å™¨æ˜¯å¦èƒ½å¤„ç†emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 6, 243544, 243691, 245561, 2], '<s> ğŸ¤—ğŸ¤”ğŸ‘€</s>')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tokenizer.encode(\"ğŸ¤—ğŸ¤”ğŸ‘€\"),embedding_tokenizer.decode([0, 6, 243544, 243691, 245561, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¢ç´¢åµŒå…¥æ¨¡å‹å¯¹emojiçš„å½±å“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def encode_sentence(sentence):\n",
    "    return torch.from_numpy(embedding_model_original.encode(sentence))\n",
    "\n",
    "emoji_list=[\"ğŸ˜­\",\"ğŸ˜¢\",\"ğŸ˜±\",\"ğŸ¤—\",\"ğŸ˜Š\",\"ğŸ¤©\",\"ğŸ‹ğŸ¼\",\"ğŸšµğŸ»â€â™‚ï¸\",\"ğŸŠğŸ»â€â™€ï¸\"]\n",
    "emoji_embedding_list=[encode_sentence(emoji) for emoji in emoji_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ä¹ˆä¸€æƒ³ç”šè‡³èƒ½ä»emojiä¸­æ‰¾å‡ºllmçš„çœ‹æ³•ã€åè§ç­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list=[\"ğŸ˜Š\",\"ğŸ˜¡\",\"ğŸ¶\",\"ğŸ±\"]\n",
    "emoji_embedding_list=[encode_sentence(emoji) for emoji in emoji_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list=[\"ğŸ˜Š\",\"ğŸ˜¡\",\"ğŸ‡¨ğŸ‡³\",\"ğŸ‡¦ğŸ‡²\",\"ğŸ‡¯ğŸ‡µ\"]\n",
    "emoji_embedding_list=[encode_sentence(emoji) for emoji in emoji_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_list=[\"ç”·äºº\",\"å¥³äºº\"]\n",
    "emoji_embedding_list=[encode_sentence(emoji) for emoji in emoji_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜­ä¸ğŸ˜¢åµŒå…¥ç›¸ä¼¼åº¦0.48  ğŸ˜­ä¸ğŸ˜±åµŒå…¥ç›¸ä¼¼åº¦0.75  ğŸ˜­ä¸ğŸ¤—åµŒå…¥ç›¸ä¼¼åº¦0.96  ğŸ˜­ä¸ğŸ˜ŠåµŒå…¥ç›¸ä¼¼åº¦0.86  ğŸ˜­ä¸ğŸ¤©åµŒå…¥ç›¸ä¼¼åº¦0.96  ğŸ˜­ä¸ğŸ‹ğŸ¼åµŒå…¥ç›¸ä¼¼åº¦0.96  ğŸ˜­ä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦1.04  ğŸ˜­ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.98  \n",
      "ğŸ˜¢ä¸ğŸ˜±åµŒå…¥ç›¸ä¼¼åº¦0.76  ğŸ˜¢ä¸ğŸ¤—åµŒå…¥ç›¸ä¼¼åº¦0.88  ğŸ˜¢ä¸ğŸ˜ŠåµŒå…¥ç›¸ä¼¼åº¦0.85  ğŸ˜¢ä¸ğŸ¤©åµŒå…¥ç›¸ä¼¼åº¦0.95  ğŸ˜¢ä¸ğŸ‹ğŸ¼åµŒå…¥ç›¸ä¼¼åº¦0.93  ğŸ˜¢ä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦1.03  ğŸ˜¢ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.99  \n",
      "ğŸ˜±ä¸ğŸ¤—åµŒå…¥ç›¸ä¼¼åº¦0.77  ğŸ˜±ä¸ğŸ˜ŠåµŒå…¥ç›¸ä¼¼åº¦0.81  ğŸ˜±ä¸ğŸ¤©åµŒå…¥ç›¸ä¼¼åº¦0.72  ğŸ˜±ä¸ğŸ‹ğŸ¼åµŒå…¥ç›¸ä¼¼åº¦0.81  ğŸ˜±ä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦0.91  ğŸ˜±ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.90  \n",
      "ğŸ¤—ä¸ğŸ˜ŠåµŒå…¥ç›¸ä¼¼åº¦0.54  ğŸ¤—ä¸ğŸ¤©åµŒå…¥ç›¸ä¼¼åº¦0.63  ğŸ¤—ä¸ğŸ‹ğŸ¼åµŒå…¥ç›¸ä¼¼åº¦0.82  ğŸ¤—ä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦0.92  ğŸ¤—ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.95  \n",
      "ğŸ˜Šä¸ğŸ¤©åµŒå…¥ç›¸ä¼¼åº¦0.69  ğŸ˜Šä¸ğŸ‹ğŸ¼åµŒå…¥ç›¸ä¼¼åº¦0.84  ğŸ˜Šä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦0.92  ğŸ˜Šä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.91  \n",
      "ğŸ¤©ä¸ğŸ‹ğŸ¼åµŒå…¥ç›¸ä¼¼åº¦0.71  ğŸ¤©ä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦0.86  ğŸ¤©ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.91  \n",
      "ğŸ‹ğŸ¼ä¸ğŸšµğŸ»â€â™‚ï¸åµŒå…¥ç›¸ä¼¼åº¦0.65  ğŸ‹ğŸ¼ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.77  \n",
      "ğŸšµğŸ»â€â™‚ï¸ä¸ğŸŠğŸ»â€â™€ï¸åµŒå…¥ç›¸ä¼¼åº¦0.39  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cos_similarity(x,y):\n",
    "    cosine_sim = torch.dot(x, y) / (torch.norm(x) * torch.norm(y))\n",
    "    return cosine_sim\n",
    "\n",
    "def L2(x,y):\n",
    "    return torch.norm(x-y,p=2)\n",
    "\n",
    "for i in range(len(emoji_list)):\n",
    "    for j in range(i+1, len(emoji_list)):\n",
    "        cos_sim = L2(emoji_embedding_list[i], emoji_embedding_list[j])  # ç¡®ä¿è¾“å…¥ä¸ºæµ®\n",
    "        print(f\"{emoji_list[i]}ä¸{emoji_list[j]}åµŒå…¥ç›¸ä¼¼åº¦{cos_sim:.2f}\",end=\"  \")\n",
    "    print()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "def de_punct(output: str):\n",
    "    rule = re.compile(r\"[^a-zA-Z0-9\\u4e00-\\u9fa5]\")\n",
    "    output = rule.sub('', output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def f1_score(output, gt):\n",
    "    output = de_punct(output)\n",
    "    gt = de_punct(gt)\n",
    "    common = Counter(output) & Counter(gt)\n",
    "\n",
    "    # Same words\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "\n",
    "    # precision\n",
    "    precision = 1.0 * num_same / len(output)\n",
    "\n",
    "    # recall\n",
    "    recall = 1.0 * num_same / len(gt)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def edit_distance(s1, s2):\n",
    "    m, n = len(s1), len(s2)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    for i in range(m + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(n + 1):\n",
    "        dp[0][j] = j\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i][j - 1], dp[i - 1][j], dp[i - 1][j - 1]) + 1\n",
    "\n",
    "    return dp[m][n]/max(len(s1),len(s2))\n",
    "\n",
    "def get_pair_distance(sentence_pair):\n",
    "    embedding1,embedding2=encode_sentence(sentence_pair)\n",
    "    return edit_distance(*sentence_pair),L2(embedding1,embedding2),f1_score(*sentence_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, tensor(0.8459), 1.0)\n",
      "(1.0, tensor(0.4579), 1.0)\n",
      "(0.42857142857142855, tensor(0.2250), 0.8571428571428571)\n",
      "(0.5, tensor(0.3034), 0.8235294117647058)\n",
      "(0.4166666666666667, tensor(0.4462), 0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "for i in [[\"èœœèœ‚\",\"èœ‚èœœ\"],[\"ç‰™åˆ·\",\"åˆ·ç‰™\"],\n",
    "[\"å¤§é²¶é±¼å’Œå°é²¶é±¼\",\"å°é²¶é±¼ä¸å¤§é²¶é±¼\"],\n",
    "[\"å¤§é²¶é±¼å’Œå°é²¶é±¼\",\"å°é²¶é±¼ä¸é²…é±¼å’Œå¤§é²¶é±¼\"],\n",
    "[\"ç³–é†‹è„†çš®èŒ„å­çš„èœè°±æ˜¯ä»€ä¹ˆ\",\"ç³–é†‹è„†çš®èŒ„å­çš„åšæ³•\"]]:\n",
    "    print(get_pair_distance(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-index-vector-stores-faiss\n",
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "faiss_index=faiss.IndexFlatL2(768) # embeddingçš„ç»´åº¦ï¼Œè¿™é‡Œç”¨çš„bce\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è‡ªå®šä¹‰æœ¬åœ°æ¨¡å‹\n",
    "https://docs.llamaindex.ai/en/stable/module_guides/models/llms/usage_custom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core import Settings\n",
    "\n",
    "def completion_to_prompt(completion):\n",
    "    # éœ€è¦ä¸¥æ ¼å¯¹åº”æ¨¡å‹çš„å¯¹è¯æ¨¡æ¿\n",
    "    return f\"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n{completion}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "def messages_to_prompt(messages):\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"system\":\n",
    "            prompt += f\"<|im_start|>system\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"user\":\n",
    "            prompt += f\"<|im_start|>user\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"assistant\":\n",
    "            prompt += f\"<|im_start|>assistant\\n{message.content}<|im_end|>\\n\"\n",
    "\n",
    "    if not prompt.startswith(\"<|im_start|>system\\n\"):\n",
    "        prompt = \"<|im_start|>system\\n<|im_end|>\\n\" + prompt\n",
    "\n",
    "    prompt = prompt + \"<|im_start|>assistant\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    model_name=\"/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b\",\n",
    "    tokenizer_name=\"/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b\",\n",
    "    context_window=2048,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 10, \"top_p\": 0.75},\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs=dict(trust_remote_code=True,torch_dtype=torch.bfloat16,do_sample=True), # åªèƒ½è¿™æ ·è®¾ç½®ï¼Œä¼šä¼ å›åŸæ¥çš„huggingfaceæ¥å£\n",
    "    tokenizer_kwargs=dict(trust_remote_code=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é£Ÿç¥é¡¹ç›®ç›®å‰ä¸»è¦ç›®æ ‡å¦‚ä¸‹ï¼š\n",
      "\n",
      "1. å»ºç«‹ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹å’Œæ£€ç´¢å¢å¼ºæŠ€æœ¯çš„ç»¼åˆé—®ç­”ç³»ç»Ÿï¼Œèƒ½å¤Ÿå¤„ç†è¯­éŸ³ã€æ–‡å­—ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥å½¢å¼ã€‚\n",
      "2. åˆ©ç”¨ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å¼€æºæ¨¡å‹internlm-chat-7bï¼ˆåŒ…å«1ä»£å’Œ2ä»£ï¼‰ï¼Œåœ¨XiaChuFang Recipe Corpusæä¾›çš„1,520,327ç§ä¸­å›½é£Ÿè°±æ•°æ®é›†ä¸Šè¿›è¡ŒLoRAå¾®è°ƒï¼Œå½¢æˆshishen2_fullæ¨¡å‹ã€‚\n",
      "3. ä½¿ç”¨langchainå°†å¾®è°ƒåçš„æ¨¡å‹ä¸chromaæˆ–faisså‘é‡æ•°æ®åº“æ•´åˆï¼Œå®ç°RAGæ£€ç´¢å¢å¼ºçš„æ•ˆæœã€‚\n",
      "4. å‰ç«¯åŸºäºstreamlitå®ç°ä¸ç”¨æˆ·çš„äº¤äº’ã€‚\n",
      "5. ç¡®ä¿æ¨¡å‹åœ¨è¾ƒå°çš„æ˜¾å­˜é…ç½®ä¸­èƒ½å¤Ÿé¡ºåˆ©è¿è¡Œï¼ŒåŒæ—¶ä¿è¯ç”Ÿå›¾å†…å®¹å‡†ç¡®ã€ç”Ÿå›¾é€Ÿåº¦å¿«ï¼Œç­‰å¾…æ—¶é—´çŸ­ã€‚\n",
      "6. ä½¿ç”¨Taiyi-Stable-Diffusion-1B-Chinese-v0.1æ¨¡å‹ä½œä¸ºæ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œç”Ÿæˆèœè°±æ›´åŠ æ¥è¿‘ä¸­å›½äººçš„ç†è§£æ°´å¹³ï¼ŒåŒæ—¶æ»¡è¶³æ—¶å»¶è¦æ±‚ã€‚\n",
      "\n",
      "7. æŒç»­ä¼˜åŒ–å’Œæ”¹è¿›ç³»ç»Ÿæ€§èƒ½ï¼Œæé«˜ç”¨æˆ·æ»¡æ„åº¦ã€‚\n",
      "8. æ¨å¹¿å’Œå®£ä¼ é¡¹ç›®ï¼Œå¸å¼•æ›´å¤šç”¨æˆ·ä½¿ç”¨ã€‚\n",
      "9. ä¸æ–­æ›´æ–°å’Œæ‰©å……æ•°æ®é›†ã€‚\n",
      "\n",
      "10. \n",
      "ğŸ“ğŸ“š ä¹¦ç”Ÿæµ¦è¯­å¤§æ¨¡å‹è®­ç»ƒè¥ç¬¬äºŒæœŸä¸»è¦æ¶µç›–ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n",
      "\n",
      "1. è½»æ¾åˆ†é’Ÿç©è½¬ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹è¶£å‘³ Demo ğŸ®\n",
      "2. XTuner å¾®è°ƒ LLM:1.8Bã€å¤šæ¨¡æ€ã€Agent ğŸ”¬\n",
      "3. LMDeploy é‡åŒ–éƒ¨ç½² LLM å®è·µ ğŸš€\n",
      "4. Lagent & AgentLego æ™ºèƒ½ä½“åº”ç”¨æ­å»º ğŸ¤–\n",
      "5. OpenCompass å¤§æ¨¡å‹è¯„æµ‹å®æˆ˜ ğŸ“Š\n",
      "6. å¤§æ¨¡å‹å¾®è°ƒæ•°æ®æ„é€  ğŸ“ˆ\n",
      "7. å½©è›‹ï¼šå¹³å°å·¥å…·ç±»è¡¥å……è¯¾ç¨‹ ğŸ\n",
      "\n",
      "è¿™äº›å†…å®¹å°†å¸¦é¢†å­¦å‘˜æ·±å…¥äº†è§£ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹çš„å„ä¸ªæ–¹é¢ï¼Œä»ç†è®ºçŸ¥è¯†åˆ°å®è·µæ“ä½œï¼Œå…¨æ–¹ä½æå‡å­¦å‘˜çš„å­¦ä¹ èƒ½åŠ›å’Œé¡¹ç›®å®è·µç»éªŒã€‚\n",
      "\n",
      "è¯¾å‰\n",
      "\n",
      "2.1.1 æ³¨å†Œç®—åŠ›å¹³å°\n",
      "\n",
      "1.è®¿é—®é—®å·åœ°å€ï¼šhttps://www.wjx.cn/vm/tUX8dEV.aspx?udsid=2146\n",
      "\n",
      "2.ç‚¹å‡»å³ä¸‹è§’â€œæŸ¥è¯¢ç»“æœâ€ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼›\n",
      "\n",
      "\n",
      "\n",
      "3.å¤åˆ¶åºå·åŠæ ¸é”€ç ï¼Œ\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "query_engine = index.as_query_engine()\n",
    "response_god = query_engine.query(\"é£Ÿç¥é¡¹ç›®ç›®å‰ä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆ,ç”¨ä¸­æ–‡åˆ†ç‚¹åˆ—å‡º\")\n",
    "response_puyu=query_engine.query(\"ä¹¦ç”Ÿæµ¦è¯­å¤§æ¨¡å‹è®­ç»ƒè¥ç¬¬äºŒæœŸä¸»è¦æœ‰ä»€ä¹ˆå†…å®¹,åˆ†ç‚¹æ¦‚æ‹¬ï¼Œå¹¶åœ¨æ¯æ¡å¤´éƒ¨æ­é…é€‚å®œçš„emoji\")\n",
    "clear_output()\n",
    "print(response_god)\n",
    "print(response_puyu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
